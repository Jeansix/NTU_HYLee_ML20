{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('train.npy', allow_pickle=True)\n",
    "test = np.load('test.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3), (10000, 32, 32, 3))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape # 训练资料是32*32的图片，rgb三个通道"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method1: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'knn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import f1_score, pairwise_distances, roc_auc_score\n",
    "from scipy.cluster.vq import vq, kmeans\n",
    "\n",
    "\n",
    "if task == 'knn':\n",
    "    x = train.reshape(len(train), -1)\n",
    "    y = test.reshape(len(test), -1)\n",
    "    # scores = list()\n",
    "    for n in range(1, 10):\n",
    "        kmeans_x = MiniBatchKMeans(n_clusters=n, batch_size=100).fit(x) # build k-means classifier\n",
    "        y_cluster = kmeans_x.predict(y) # test on y\n",
    "        y_dist = np.sum(np.square(kmeans_x.cluster_centers_[y_cluster] - y), axis=1) # calculate distance from cluster centroid\n",
    "        y_pred = y_dist\n",
    "        \n",
    "    #   score = f1_score(y_label, y_pred, average='micro')\n",
    "    #   score = roc_auc_score(y_label, y_pred, average='micro')\n",
    "    #   scores.append(score)\n",
    "    # print(np.max(scores), np.argmax(scores))\n",
    "    # print(scores)\n",
    "    # print('auc score: {}'.format(np.max(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method2: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'pca'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "if task == 'pca':\n",
    "    x = train.reshape(len(train), -1)\n",
    "    y = test.reshape(len(test), -1)\n",
    "    pca = PCA(n_components=2).fit(x)\n",
    "\n",
    "    y_projected = pca.transform(y)\n",
    "    y_reconstructed = pca.inverse_transform(y_projected)  \n",
    "    dist = np.sqrt(np.sum(np.square(y_reconstructed - y).reshape(len(y), -1), axis=1))\n",
    "    \n",
    "    y_pred = dist\n",
    "    # score = roc_auc_score(y_label, y_pred, average='micro')\n",
    "    # score = f1_score(y_label, y_pred, average='micro')\n",
    "    # print('auc score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.694404509963118"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method3: AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'ae'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model1: fcn_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "#fcn_autoencoder and vae are from https://github.com/L1aoXingyu/pytorch-beginner\n",
    "#conv_autoencoder is from https://github.com/jellycsc/PyTorch-CIFAR-10-autoencoder/\n",
    "\n",
    "class fcn_autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fcn_autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(32 * 32 * 3, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(64, 12), \n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(12, 3)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(128, 32 * 32 * 3), \n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model2: conv_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(conv_autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 12, 4, stride=2, padding=1),            # [batch, 12, 16, 16]，16=（32-4+2）/2+1\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(12, 24, 4, stride=2, padding=1),           # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(24, 48, 4, stride=2, padding=1),           # [batch, 48, 4, 4]\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),  # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),  # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),   # [batch, 3, 32, 32]\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model3: VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(32*32*3, 400)\n",
    "        self.fc21 = nn.Linear(400, 20)\n",
    "        self.fc22 = nn.Linear(400, 20)\n",
    "        self.fc3 = nn.Linear(20, 400)\n",
    "        self.fc4 = nn.Linear(400, 32*32*3)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if torch.cuda.is_available():\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return F.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "\n",
    "def loss_vae(recon_x, x, mu, logvar, criterion):\n",
    "    \"\"\"\n",
    "    recon_x: generating images\n",
    "    x: origin images\n",
    "    mu: latent mean\n",
    "    logvar: latent log variance\n",
    "    \"\"\"\n",
    "    mse = criterion(recon_x, x)  # mse loss\n",
    "    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "    # KL divergence\n",
    "    return mse + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type conv_autoencoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/66], loss:0.0869\n",
      "epoch [2/66], loss:0.0639\n",
      "epoch [3/66], loss:0.0542\n",
      "epoch [4/66], loss:0.0474\n",
      "epoch [5/66], loss:0.0379\n",
      "epoch [6/66], loss:0.0332\n",
      "epoch [7/66], loss:0.0346\n",
      "epoch [8/66], loss:0.0286\n",
      "epoch [9/66], loss:0.0253\n",
      "epoch [10/66], loss:0.0257\n",
      "epoch [11/66], loss:0.0236\n",
      "epoch [12/66], loss:0.0233\n",
      "epoch [13/66], loss:0.0240\n",
      "epoch [14/66], loss:0.0250\n",
      "epoch [15/66], loss:0.0240\n",
      "epoch [16/66], loss:0.0221\n",
      "epoch [17/66], loss:0.0229\n",
      "epoch [18/66], loss:0.0197\n",
      "epoch [19/66], loss:0.0197\n",
      "epoch [20/66], loss:0.0205\n",
      "epoch [21/66], loss:0.0193\n",
      "epoch [22/66], loss:0.0200\n",
      "epoch [23/66], loss:0.0172\n",
      "epoch [24/66], loss:0.0172\n",
      "epoch [25/66], loss:0.0175\n",
      "epoch [26/66], loss:0.0155\n",
      "epoch [27/66], loss:0.0157\n",
      "epoch [28/66], loss:0.0163\n",
      "epoch [29/66], loss:0.0172\n",
      "epoch [30/66], loss:0.0155\n",
      "epoch [31/66], loss:0.0144\n",
      "epoch [32/66], loss:0.0156\n",
      "epoch [33/66], loss:0.0141\n",
      "epoch [34/66], loss:0.0156\n",
      "epoch [35/66], loss:0.0158\n",
      "epoch [36/66], loss:0.0157\n",
      "epoch [37/66], loss:0.0128\n",
      "epoch [38/66], loss:0.0160\n",
      "epoch [39/66], loss:0.0136\n",
      "epoch [40/66], loss:0.0133\n",
      "epoch [41/66], loss:0.0138\n",
      "epoch [42/66], loss:0.0142\n",
      "epoch [43/66], loss:0.0118\n",
      "epoch [44/66], loss:0.0128\n",
      "epoch [45/66], loss:0.0129\n",
      "epoch [46/66], loss:0.0124\n",
      "epoch [47/66], loss:0.0123\n",
      "epoch [48/66], loss:0.0131\n",
      "epoch [49/66], loss:0.0126\n",
      "epoch [50/66], loss:0.0119\n",
      "epoch [51/66], loss:0.0131\n",
      "epoch [52/66], loss:0.0132\n",
      "epoch [53/66], loss:0.0118\n",
      "epoch [54/66], loss:0.0125\n",
      "epoch [55/66], loss:0.0144\n",
      "epoch [56/66], loss:0.0121\n",
      "epoch [57/66], loss:0.0112\n",
      "epoch [58/66], loss:0.0106\n",
      "epoch [59/66], loss:0.0112\n",
      "epoch [60/66], loss:0.0110\n",
      "epoch [61/66], loss:0.0114\n",
      "epoch [62/66], loss:0.0114\n",
      "epoch [63/66], loss:0.0130\n",
      "epoch [64/66], loss:0.0098\n",
      "epoch [65/66], loss:0.0103\n",
      "epoch [66/66], loss:0.0120\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "\n",
    "if task == 'ae':\n",
    "    # set hyper parameters\n",
    "    num_epochs = 66\n",
    "    batch_size = 128\n",
    "    learning_rate = 1e-4\n",
    "\n",
    "    #{'fcn', 'cnn', 'vae'} \n",
    "    model_type = 'cnn' \n",
    "    \n",
    "    # prepare data\n",
    "    x = train\n",
    "    if model_type == 'fcn' or model_type == 'vae':\n",
    "        x = x.reshape(len(x), -1) # cnn不用展开，直接卷积\n",
    "        \n",
    "    data = torch.tensor(x, dtype=torch.float)\n",
    "    train_dataset = TensorDataset(data)\n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "    # define model\n",
    "    model_classes = {'fcn':fcn_autoencoder(), 'cnn':conv_autoencoder(), 'vae':VAE()}\n",
    "    model = model_classes[model_type].cuda()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    best_loss = np.inf\n",
    "    # start training\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for data in train_dataloader:\n",
    "            # data preprocess\n",
    "            if model_type == 'cnn':\n",
    "                img = data[0].transpose(3, 1).cuda()\n",
    "            else:\n",
    "                img = data[0].cuda()\n",
    "            # ===================forward=====================\n",
    "            output = model(img)\n",
    "            if model_type == 'vae':\n",
    "                loss = loss_vae(output[0], img, output[1], output[2], criterion)\n",
    "            else:\n",
    "                loss = criterion(output, img)\n",
    "            # ===================backward====================\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # ===================save====================\n",
    "            if loss.item() < best_loss:\n",
    "                best_loss = loss.item()\n",
    "                torch.save(model, 'best_model_{}.pt'.format(model_type))\n",
    "        # ===================log========================\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == 'ae':\n",
    "    if model_type == 'fcn' or model_type == 'vae':\n",
    "        y = test.reshape(len(test_tmp), -1)\n",
    "    else:\n",
    "        y = test\n",
    "    # prepare testing data\n",
    "    data = torch.tensor(y, dtype=torch.float)\n",
    "    test_dataset = TensorDataset(data)\n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "    test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size)\n",
    "    # load model\n",
    "    model = torch.load('best_model_{}.pt'.format(model_type), map_location='cuda')\n",
    "    model.eval()\n",
    "    reconstructed = list()\n",
    "    # collect reconstructed images\n",
    "    for i, data in enumerate(test_dataloader): \n",
    "        if model_type == 'cnn':\n",
    "            img = data[0].transpose(3, 1).cuda() # 第一维是in_channels\n",
    "        else:\n",
    "            img = data[0].cuda()\n",
    "        output = model(img)\n",
    "        if model_type == 'cnn':\n",
    "            output = output.transpose(3, 1)\n",
    "        elif model_type == 'vae':\n",
    "            output = output[0]\n",
    "        reconstructed.append(output.cpu().detach().numpy())\n",
    "\n",
    "    reconstructed = np.concatenate(reconstructed, axis=0)\n",
    "    # calculate differnence\n",
    "    anomality = np.sqrt(np.sum(np.square(reconstructed - y).reshape(len(y), -1), axis=1))\n",
    "    y_pred = anomality\n",
    "    with open('prediction.csv', 'w') as f:\n",
    "        f.write('id,anomaly\\n')\n",
    "        for i in range(len(y_pred)):\n",
    "            f.write('{},{}\\n'.format(i+1, y_pred[i]))\n",
    "    # score = roc_auc_score(y_label, y_pred, average='micro')\n",
    "    # score = f1_score(y_label, y_pred, average='micro')\n",
    "    # print('auc score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch-gpu-py36)",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
